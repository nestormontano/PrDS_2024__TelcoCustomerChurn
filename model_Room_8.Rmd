---
title: "model_room_8"
author: "Juan Carlos Jimenez y Juan José Espín"
output:
  html_document: default
  pdf_document: default
date: "2024-02-17"
---

---
title: "Modelo Room 8"
output:
  html_document:
    df_print: paged
editor_options:
  chunk_output_type: console
---

#Librarias

```{r message=FALSE, warning=FALSE, paged.print=FALSE}
library(tidyverse)
library(magrittr)
library(skimr)
library(janitor)
library(tidymodels)
library(ranger)
library(xgboost)
library(vip)
```

#Cargar datos

```{r}
data <- read_csv('Data/WA_Fn-UseC_-Telco-Customer-Churn.csv',
                 show_col_types = FALSE)
```

#Verificar y corregir columnas

### Verificar base de datos con glimpse
```{r}
data %>% 
        glimpse
        
```

### Verificar base de datos y convertir en factor
```{r}


data %>% 
        summarise_all(list(
                .n=~sum(!is.na(.)),
                .na=~sum(is.na(.)),
                .min=~min(.,na.rm = T),
                .max=~max(.,na.rm = T),
                .clase=~class(.),
                .valor_distinto=~n_distinct(.)
        )) %>% mutate(across(everything(),~as.character(.))) %>% 
        pivot_longer(everything(),
                     names_to = c("varible",".value"),
                     names_sep = c("_\\.")) %>% gt::gt()
     
#Convertir a factor
data %>%
  mutate( Churn = factor(Churn,
  levels= c("Yes","No"),
  labels= c("si", "no"))
  ) -> data


data %>%
  mutate(
    SeniorCitizen = factor(SeniorCitizen, 
                           levels = c(0, 1), labels = c('no', 'si')),
    gender = factor(gender,
                    levels = c('Female', 'Male'), labels = c('Mujeres', 'Hombres')),
    Partner = factor(Partner,
                     levels = c('Yes', 'No'), labels = c('si', 'No')),
    Dependents = factor(Dependents,
                        levels = c('Yes', 'No'), labels = c('si', 'No')),
    PhoneService = factor(PhoneService,
                          levels = c('Yes', 'No'), labels = c('si', 'No')),
    PaperlessBilling = factor(PaperlessBilling,
                              levels = c('Yes', 'No'), labels = c('si', 'No')),
    MultipleLines = factor(MultipleLines, 
                           levels = c('Yes', 'No', "No phone service"), labels = c('si', 'no', 'sin servicio')),
    InternetService = factor(InternetService, 
                             levels = c('DSL', 'Fiber optic', 'No'), labels = c('DSL', 'Fibra optica', 'No')),
    OnlineSecurity = factor(OnlineSecurity,
                            levels = c('No', 'Yes', 'No internet service'), labels = c('No', 'Yes', 'sin servicio')),
    OnlineBackup = factor(OnlineBackup, 
                          levels = c('Yes', 'No', 'No internet service'), labels = c('si', 'no', 'sin servicio')),
    DeviceProtection = factor(DeviceProtection, 
                              levels = c('Yes', 'No', 'No internet service'), labels = c('si', 'no', 'sin servicio')),
    TechSupport = factor(TechSupport, 
                         levels = c('Yes', 'No', 'No internet service'), labels = c('si', 'no', 'sin servicio')),
    StreamingTV = factor(StreamingTV, 
                         levels = c('Yes', 'No', 'No internet service'), labels = c('si', 'no', 'sin servicio')),
    StreamingMovies = factor(StreamingMovies, 
                             levels = c('Yes', 'No', 'No internet service'), labels = c('si', 'no', 'sin servicio')),
    Contract = factor(Contract, 
                      levels = c('Month-to-month', 'One year', 'Two year'), labels = c('mes a mes', 'un año', 'dos años')),
    PaymentMethod = factor(PaymentMethod, 
                           levels = c('Electronic check', 'Mailed check', 'Bank transfer (automatic)', 'Credit card (automatic)'),
                           labels = c('cheque electronico', 'cheque mail', 'transferencia bancaria', 'transferencia automatica'))
  ) -> data


```

#EDA

### EDA Univariado

#### Todas las variables

```{r}
skim(data)
```

#### Posibles outliers

```{r warning=FALSE}
data %>% 
  reframe( 
    tibble(
      Descrip= c('P_0', 'P_02', 'P_25', 'P_50' , 'P_75', 'P_98', 'P_100') ,
      Valor= quantile( TotalCharges, c(0, 0.2, 0.25, 0.50 ,0.75, 0.98, 1), na.rm= T)
    )
    ) %>% 
        gt::gt()

#Media por Partner
data %>% 
        group_by(Partner) %>% 
        summarise(media=mean(TotalCharges,
                          na.rm =T )) %>% 
        gt::gt()

#Distribuciòn de TotalCharges por Partner
data %>% 
        ggplot(aes(TotalCharges,
                   color=Partner))+
        geom_density()+
        scale_y_continuous(labels = scales::number_format())+
        theme_dark()
```

Existe una diferencia importante en los registros de dinero cobrado a los clientes al considerar aquellos que tienen pareja. Al revisar el gráfico anterior, se evidencia que las personas que informaron tener pareja son las que presentan los cobros más altos. Esto se refleja en la distribución, donde se observa una densidad mayor para valores altos en comparación con las personas que declararon no tener pareja.



### EDA Bivariado

#### Churn vs SeniorCitizen

```{r}
data %>%
  group_by(SeniorCitizen, Churn) %>%
  summarise(
    N = n(),
    Porc = round(100*N/nrow(data),2)
  ) %>%
  mutate(Porc_grupo = round(100*N/sum(N),2)) -> valores_Sc

valores_Sc %>% 
        ungroup() %>% 
        gt::gt()
```

```{r echo=T}
# Comentado por conflictos con paquete
# tigerstats::rowPerc(xtabs(~SeniorCitizen+Churn, data=data) )
```

#### Churn vs SeniorCitizen vs Porc_grupo

```{r}
ggplot(valores_Sc, aes(x = SeniorCitizen, y = Porc_grupo, fill = Churn)) +
  geom_col(stat = "identity", position = "dodge") +
  geom_text(aes(label = Porc_grupo), vjust = 1.5,
            position = position_dodge(.9))
```
De los adultos mayores el 41% abandonó el servicio, mientras que de los no adultos mayores apenas un 24% abandonó el servicio. Aparentemente, un adulto mayor tiene mayor probabilidad de abandonar el servicio.

#### Churn vs MultipleLines

```{r message=FALSE}
valores_Ml <- data %>%
        count(Churn,MultipleLines) %>% 
        group_by(Churn) %>% 
        mutate(n_chur=sum(n),
               porcentaje_personas=n/n_chur) %>% 
        ungroup() 

valores_Ml %>% 
        gt::gt()%>% 
        gt::fmt_percent(columns=porcentaje_personas)
```

######Gráfico

```{r}
valores_Ml %>% 
        ggplot(aes(Churn, y = porcentaje_personas, fill = MultipleLines)) +
        geom_col(position = "dodge") +
        geom_text(aes(label = scales::percent(porcentaje_personas,accuracy = 0.01)), vjust = -0.8,
                  position = position_dodge(.9))
```

Entre las categorías de MultipleLines no hay mayor diferencia, entre los que abandonan o no el servicio. Los porcentajes son muy parecidos.

#### Churn vs TechSupport

```{r}

data %>%
        count(Churn,TechSupport) %>% 
        group_by(Churn) %>% 
        mutate(n_chur=sum(n),
               porcentaje_personas=n/n_chur) %>% 
        ungroup() %>% 
        ggplot(aes(Churn,
                   porcentaje_personas,
                   fill = TechSupport)) +
        geom_col(position = "dodge") +
        geom_text(aes(label = scales::percent(porcentaje_personas,
                                              accuracy = 0.01)),
                  vjust = -0.8,
                  position = position_dodge(.9)) 
```
Las personas que se van de la compañía en promedio el 77.37% no tienen soporte técnico y solo el 16.59% de los que se van indican tener soporte técnico.

#### Churn vs PaymentMethod

```{r}

data %>%
        count(Churn,PaymentMethod) %>% 
        group_by(Churn) %>% 
        mutate(n_chur=sum(n),
               porcentaje_personas=n/n_chur) %>% 
        ungroup() %>% 
        ggplot(aes(Churn,
                   porcentaje_personas,
                   fill = PaymentMethod)) +
        geom_col(position = "dodge") +
        geom_text(aes(label = scales::percent(porcentaje_personas,
                                              accuracy = 0.1)),
                  vjust = -0.8,
                  position = position_dodge(.9)) 

```

A excepción de los que pagan con cheque electrónico los porcentajes de abandono son muy parecidos. En el caso de los que pagan con cheque electrónico un 57.3% abandona el servicio.


#### Churn vs Dependents

```{r}
data %>% tabyl(Churn, Dependents ) -> t1

t1 %>% adorn_totals(c("row", "col")) %>% adorn_percentages("all") %>%
adorn_pct_formatting(rounding = "half up", digits = 0) %>% adorn_ns() %>%
  adorn_title("combined") %>% knitr::kable()

data %>% count(Churn, Dependents) %>%
  mutate(porc = n / sum(n)) %>% 
  ggplot(aes(fill=Dependents, y=porc, x=Churn)) + 
    geom_col(position="stack") +
    geom_text(aes(label=scales::percent(porc)),position = position_stack(vjust=0.5))+
  scale_y_continuous(labels = scales::percent_format()) 


```

De la muestra analizada alrededor del 27% corresponde a individuos que dejaron sus planes en el último mes. Además se conoce que el 4,6% de estos individuos contaban con personas dependientes.

#### Churn vs OnlineSecurity

```{r}


data %>% tabyl(Churn,OnlineSecurity ) -> t2

t2 %>% adorn_totals(c("row", "col")) %>% adorn_percentages("all") %>%
adorn_pct_formatting(rounding = "half up", digits = 0) %>% adorn_ns()%>% adorn_title("combined")%>% knitr::kable()


data %>% count(Churn, OnlineSecurity) %>%
  mutate(porc = n / sum(n)) %>% 
  ggplot(aes(fill=OnlineSecurity, y=porc, x=Churn)) + 
    geom_col(position="stack") +
    geom_text(aes(label=scales::percent(porc)),position = position_stack(vjust=0.5))+
  scale_y_continuous(labels = scales::percent_format()) 


```

El 20,74% de los indviduos analizados y que abandonaron el servicio no contaban con seguridad en línea. Por otro lado aquellos que no salieron del plan reflejaron una participación similar con relación al servicio de seguridad en línea.

#### Churn vs StreamingMovies

```{r}

data %>% tabyl(Churn,StreamingMovies) -> t3

t3 %>% adorn_totals(c("row", "col")) %>% adorn_percentages("all") %>%
adorn_pct_formatting(rounding = "half up", digits = 0) %>% adorn_ns()%>% adorn_title("combined")%>% knitr::kable()


data %>% count(Churn, StreamingMovies) %>%
  mutate(porc = n / sum(n)) %>% 
  ggplot(aes(fill=StreamingMovies, y=porc, x=Churn)) + 
    geom_col(position="stack") +
    geom_text(aes(label=scales::percent(porc)),position = position_stack(vjust=0.5))+
  scale_y_continuous(labels = scales::percent_format()) 


```

El 13,32% de los indviduos analizados y que abandonaron el servicio no contaban con servicio de Streaming Movies. Sin embargo, tanto para el grupo que abandonaron o mantuvieron el servicio no se evidencia una importancia relevante para su salidad del plan.

#### Churn vs Total Charges

```{r warning=FALSE}

data %>%  group_by(Churn) %>% 
  summarise(n = n(),
            promedio = mean(TotalCharges,na.rm = T),
            n_missing = sum(is.na(TotalCharges)),
            desv = sd(TotalCharges, na.rm =T)) -> t4
t4 %>% 
        gt::gt()

data %>%
  ggplot(aes(x = Churn, y = TotalCharges, fill = Churn)) +
  geom_boxplot() +
  stat_summary(fun = mean, geom = "point", shape = 3, size = 3,
               color = "white", position = position_dodge(width = 0.75)) +
  labs(title = "Churn vs Total Charges",
       x = "Churn",
       y = "Total Charges") +
        theme_minimal()

```

En promedio el gasto total en el servicio de telecomunicaciones para los individuos que salieron del plan es inferior por usuario en alrededor de USD 1000. Para los usuarios que salieron del servicio se evidencia datos atípicos elevados que alcanzan los valores máximos de los usarios que no salieron del servicio. Cabe señalar que, para los usuarios que no abandoron el servicio su extipendio total del plan se concentra entre el rango intercuartílico. Adicionalmente, se observa que la variable gasto total cuenta con 11 valores perdidos.

### EDA Multivariado

#### Churn vs MonthlyCharges vs PaymentMethod

```{r}
ggplot(data, aes(x = Churn, y = MonthlyCharges, fill = PaymentMethod)) +
  geom_boxplot()
```

Los montos de pago de aquellos que abandonan el servicio son superiores a aquellos que permanecen con excepción de los que pagan por cheque electrónico.

#### Churn vs MonthlyCharges vs Dependents

```{r}
data %>%  group_by(Churn,Dependents) %>% 
    summarise(n = n(),
            promedio = mean(MonthlyCharges,na.rm = T),
            n_missing = sum(is.na(MonthlyCharges)),
            desv = sd(MonthlyCharges, na.rm =T),
            .groups="drop")  -> t5
t5 %>% 
        gt::gt() %>% 
        gt::fmt_number(columns = c(promedio,desv),
                       decimals = 2)

data %>%
  ggplot(aes(x = Churn, y = MonthlyCharges, fill = Dependents)) +
  geom_boxplot() +
  stat_summary(fun = mean, geom = "point", shape = 3, size = 3, color = "white", position = position_dodge(width = 0.75)) +
  labs(title = "Monthtly Charges for Dependents vs Churn",
       x = "Churn",
       y = "Monthly Charges")

```

La distribución del gasto mensual de aquellos individuos que no salieron del plan se concentra dentro del cuartil 1 y cuartil 3, además entre el máximo y mínimo de los que dejaron el servicio respecto de los que se quedaron no se verifica mayor diferencia. Es importante destacar que, tanto el promedio como la mediana del pago mensual es superior en los individuos que salieron del plan de los que se quedaron, no obstante no se verifica mayor diferencia respecto de contar o no con dependientes en los usuarios que abandonaron el plan.


# Matriz de Correlación

```{r message=FALSE, warning=FALSE}
data %>%  select_if(where(is.numeric)) %>% GGally::ggpairs()

```

Según el gráfico anterior existe una alta correlación positiva entre las variables TotalChanges y tenure, con 0.826, seguida de la correlación entre las variables TotalChages y MonthyChanges, con una correlación moderada de 0.651.


# Revisión del balanceo de datos

```{r}
data %>% 
  group_by(Churn) %>% 
  count(name = "frec") %>%
        ungroup() %>%
        mutate( Porc= frec/sum(frec)) %>% 
        gt::gt() %>% 
        gt::fmt_percent(columns=Porc)

data %>%
group_by(Churn) %>%
count( name = 'frec') %>%
ungroup() %>%
mutate( Porc= frec/sum(frec)) %>%
ggplot( aes(x= Churn, y= Porc)) +
geom_segment( aes(xend= Churn, y=0, yend=Porc),
color= "steelblue", linewidth= 1) +
geom_point( size=5, color= "steelblue") +
coord_flip() +
scale_y_continuous( labels = percent_format()) +
labs(title= 'Porcentaje de Clientes que Abandonan',
y= "Porcentaje", x= "Churn") +
theme_bw()

```

El porcentaje de clientes que abandonan el servicio de telecomunicaciones es aproximadamente 3 a 1 en el muestra de análisis.


# MODELAMIENTO

### Train - Test Split

```{r}
#data %>% select(-customerID) -> data

set.seed(1234) # Semilla para aleatorios
split <- data %>%
initial_split(
prop = 0.8, # Porcentaje al train
strata = Churn # Estratificación del muestreo
)




```

### Data de entrenamiento

```{r}
train <- training(split)
dim(train)
```

### Data de prueba (test)

```{r}
test <- testing(split)
dim(test)
```

### Preprocesamiento

#### Receipe y Balanceo de datos

```{r}
receta <- train %>%
recipe(Churn ~ . ) %>% ## Crea la receta
## Eliminar variables que no usaremos
step_rm(customerID) %>%
## Crear nuevas variables (insight desde el EDA)
# step_mutate( account_length_anio= account_length/12 )
## Imputar los datos
# step_impute_mean()
step_impute_knn(TotalCharges ) %>%
## Estandarizacion/Normalizacion de numericas
step_normalize( all_numeric(), -all_outcomes()) %>%
## Crear una categoría "otros" que agrupe a categorias pequeñas
step_other(all_nominal(), -all_outcomes() , threshold = 0.07, other = "otros") %>%
## Crear una categoría "new" para observaciones con labels "no muestreados"
step_novel(all_nominal(), -all_outcomes() , new_level = "new") %>%
## Crear variables indicadoras para cada categoría
step_dummy(all_nominal(), -all_outcomes() ) %>% # Dummy
## Eliminar automáticamente variables con alta correlacion
## para evitar la multicolinealidad xi ~ xj
# step_corr(all_numeric(), -all_outcomes(), threshold = 0.9) %>%
## Tambien podemos eliminar variables con multicolinealidad "a mano"
#step_rm(total_day_charge, total_eve_charge,
#total_night_charge, total_intl_charge) %>% # Eliminar
## Eliminar columnas con varianza cercana a cero
step_nzv(all_predictors()) %>% 
themis::step_upsample(Churn, over_ratio = 0.9, skip= TRUE, seed= 123)  

receta

```

#### Entrenamiento y ajuste de Hiperparámetro

```{r}

set.seed(1234)
cv <- vfold_cv(train, v = 5, repeats = 1, strata = Churn)
cv 


```

### Métricas

```{r}
metricas <- metric_set(accuracy, sens, spec, bal_accuracy)
metricas


```

# Modelamiento - Random Forest

### Especificacion del modelo*

```{r}
rf_sp <-
  rand_forest(
  mtry = tune(), trees = tune(), min_n = tune() ) %>%
  set_engine("ranger", importance = "impurity") %>%
  set_mode("classification")

rf_sp

```

### Work Flow

```{r}
rf_wflow <-
  workflow() %>%
  add_recipe(receta) %>%
  add_model(rf_sp) 
  rf_wflow


```

### Afinamiento de Hiperpárametros

```{r warning=FALSE}
set.seed(123)
rf_grid <- rf_sp %>%
## preguntamos los parametros tuneables del modelo
parameters() %>%
## Vamos a definir un rango para el min_n y mtry
update(min_n= min_n( range= c(70, 170)),
mtry= mtry( range= c(4, 7))) %>%
grid_latin_hypercube(size = 10) #preguntar como se construye la malla

rf_grid %>% 
        gt::gt()

```

La data luego de aplicar la receta registra 31 variables, por tanto, se utiliza como criterio para establecer el hiperpárametro "mtry" la raíz cuadrada del número de variables analizadas siendo esta igual a 5,56. Con la finalidad de contar con un rango para la elección de variables se establece entre 4 a 7. 

###Paralelización

```{r}
#parallel::detectCores(logical=FALSE)

```

### Entrenamiento de Malla de Búsqueda en la Crossvalidation

```{r}
set.seed(123)
rf_tuned <- tune_grid(
        rf_wflow, ## Modelo
        resamples= cv, ## Crossvalidation
        grid = rf_grid, ## Malla de Busqueda
        metrics = metricas, ## Metricas
        control= control_grid(allow_par = T, save_pred = T) ## Paralel y Pred
)
rf_tuned

```

### Evaluación de modelos Evaluamos que modelo resulto mejor

```{r}
show_best(rf_tuned, metric = 'accuracy', n = 10)%>% 
        gt::gt() %>% 
        gt::fmt_percent(columns = mean,
                        decimals = 2)
```

```{r}
show_best(rf_tuned, metric = 'sens', n = 10) %>% 
        gt::gt() %>% 
        gt::fmt_percent(columns = mean,
                        decimals = 2)
```

```{r}
show_best(rf_tuned, metric = 'spec', n = 10)%>% 
        gt::gt() %>% 
        gt::fmt_percent(columns = mean,
                        decimals = 2)

```

```{r}
show_best(rf_tuned, metric = 'bal_accuracy', n = 10)%>% 
        gt::gt() %>% 
        gt::fmt_percent(columns = mean,
                        decimals = 2)
```

Revisando los resultados de las métricas de evaluación del modelo y considerando que es de interés para le empresa contar con la mejor estimación de los individuos que realmente abandonan el servicio se selecciona como referencia los hiperpárametros del modelo número 6 que presenta los mejores resultados en sensibilidad, para ajustar el modelo final.

### Nueva Malla de Búsqueda

```{r}

set.seed(123)

rf_grid_2 <- crossing(
  min_n = seq(114, 118, 2),
  mtry = c(4, 5),
  trees= seq(1270, 1570, 100)
)

rf_grid_2%>% 
        gt::gt()

```

### Entrenamiento de Malla de Busqueda en la Crossvalidation

```{r}

set.seed(123)
rf_tuned_2 <- tune_grid(
  rf_wflow, ## Modelo
  resamples= cv, ## Crossvalidation
  grid = rf_grid_2, ## Malla de Busqueda
  metrics = metricas, ## Metricas
  control= control_grid(allow_par = T, save_pred = T) ## Paralel y Pred
)
rf_tuned_2

```

Evaluamos que modelo resulto mejor de la segunda grilla de hiperpárametros

```{r}
show_best(rf_tuned_2, metric = 'accuracy', n = 10)%>% 
        gt::gt() %>% 
        gt::fmt_percent(columns = mean,
                        decimals = 2)
```

```{r}
show_best(rf_tuned_2, metric = 'sens', n = 10)%>% 
        gt::gt() %>% 
        gt::fmt_percent(columns = mean,
                        decimals = 2)
```

```{r}
show_best(rf_tuned_2, metric = 'spec', n = 10)%>% 
        gt::gt() %>% 
        gt::fmt_percent(columns = mean,
                        decimals = 2)
```

```{r}
show_best(rf_tuned_2, metric = 'bal_accuracy', n = 10)%>% 
        gt::gt() %>% 
        gt::fmt_percent(columns = mean,
                        decimals = 2)
```

Se verifica que el modelo obtenido de la primera malla de hiperparámetros tiene mejores resultados en sensibilidad que la segunda grilla, por tanto se selecciona el mejor modelo del primer ejercicio. 
### Modelo final

```{r}
## Definir la mejor combinacion
rf_pars_fin <- select_best(rf_tuned, metric = 'sens')
## Finalizar (darle valores a parametros tuneables) el workflow
rf_wflow_fin <-
rf_wflow %>%
  finalize_workflow(rf_pars_fin)
rf_wflow_fin
```

### Entrenamiento del modelo

Entrenar el modelo final

```{r}
rf_fitted <- fit(rf_wflow_fin, train)
rf_fitted


```

### Modelo sin workflow

```{r}
rf_model_fin <- extract_fit_parsnip(rf_fitted)
```

### Evaluación del Modelo

Evaluación en la data de entrenamiento

```{r}

train %>%
predict(rf_fitted , new_data = . ) %>%
mutate(Real= train$Churn) %>%
conf_mat(truth = Real, estimate = .pred_class ) %>%
summary

```

### Evaluación en la data de prueba

```{r}
test %>%
predict(rf_fitted, new_data = . ) %>%
mutate(Real= test$Churn) %>%
  conf_mat(truth = Real, estimate = .pred_class ) %>%
summary
```

### ¿Que variables pueden estar relacionadas más con el abandono de clientes?

```{r}
library(vip)
rf_model_fin %>%
  vip(geom = "point")
```

# Modelo Boosting XGBoost*

Como parte del ejercicio de selección del mejor modelo para la determinación de la mejor estrategia para retención de clientes, se utiliza el algoritmo XGboost con la finalidad de elegir el modelo con mayor poder predictivo.

Para tal efecto, la aplicación del algoritmo XGboost inicia a partir de la receta establecida para los datos de abandono de clientes del servicio de telecomunicaciones.

### Especificación del modelo

```{r}

xgb_sp <- boost_tree(mtry = tune(), trees = tune(),
  loss_reduction = tune(), learn_rate= tune() ) %>%
  set_engine("xgboost") %>%
  set_mode("classification")

xgb_sp %>%
  translate()



```

### Afinamiento de Malla de búsqueda

Previo a establecer la malla de búsqueda el algoritmo requiere la data incorporada las funciones establecidas en la receta, por tal motivo se aplica prep y bake. Posteriormente, se obtiene la malla de búsqueda

```{r}

receta_prep = prep(receta, train)
finalize(mtry(), bake(receta_prep, new_data = NULL ))

set.seed(123)
xgb_grid <- xgb_sp %>%
  parameters() %>%
  finalize(bake(receta_prep, new_data = NULL)) %>%
  grid_latin_hypercube(size = 20)

xgb_grid


```

### Work Flow

```{r}

xgb_wflow <-
  workflow() %>%
  add_recipe(receta) %>%
  add_model(xgb_sp)

xgb_wflow
```

### Entrenamiento de Malla de Busqueda en la Crossvalidation - Xgboost

```{r}

set.seed(123)

xgb_tuned <- tune_grid(
  xgb_wflow,
  resamples= cv,
  grid = xgb_grid,
  metrics = metricas,
  control= control_grid(allow_par = T, save_pred = T)
  )

xgb_tuned


```

### Mejor modelo

Evaluamos que modelo resulto mejor

```{r}
show_best(xgb_tuned, metric = 'accuracy', n = 10)

```

```{r}
show_best(xgb_tuned, metric = 'sens', n = 10)

```

```{r}
show_best(xgb_tuned, metric = 'spec', n = 10)

```

```{r}
show_best(xgb_tuned, metric = 'bal_accuracy', n = 10)
```

### Selección del modelo final

La selección de los hipepáramestros es con base al mejor modelo de sensibilidad y "bal_accuracy", por tanto se el modelo final resulta ser el modelo 04, no se realizá un proceso búsqueda manual del mejor modelo debido a la amplitud de valores que puede tomar el learn_rate y la función de costo, así como la discrecionalidad de la amplitud de búsqueda.

```{r}
xgb_pars_fin <- select_best(xgb_tuned, metric = 'sens')
xgb_wflow_fin <-
  xgb_wflow %>%
  finalize_workflow(xgb_pars_fin)

xgb_wflow_fin

```

### Entrenar el modelo final

```{r}
xgb_fitted <- fit(xgb_wflow_fin, train)
xgb_fitted
```

### Selección del modelo

```{r}

xgb_model_fin <- pull_workflow_fit(xgb_fitted)
xgb_model_fin

```

### Evaluación del modelo en la data de entrenamiento y prueba

```{r}
train %>%
  predict(xgb_fitted , new_data = . ) %>%
  mutate(Real= train$Churn) %>%
  conf_mat(truth = Real, estimate = .pred_class ) %>%
  summary


```

```{r}

test %>%
  predict(xgb_fitted , new_data = . ) %>%
  mutate(Real= test$Churn) %>%
  conf_mat(truth = Real, estimate = .pred_class ) %>%
  summary

```

### Importancia de las variables en el modelo

```{r}

vip(xgb_model_fin)

```

Analizando la importancia de las variables en el modelo se verifica que el gasto mensual y total presentan una alta importancia en las variables sin embargo el gasto total es una combinación lineal del gasto mensual, por lo que se podría excluir del modelo una de las variabales para probar si incrementa su capacidad de predicción con respecto a sensibilidad y bal_accuracy.

# Conclusión

Del análisis realizado se evidencia que ambos modelos (Random Forest y Xgboost ) presentan muy buena estimación con relación a sensibilidad, es decir con la capacidad de predicción de los individuos que abandonan el servicio, no obstante Xgboost presenta un resultado superior en el test de prueba (0.7459 \> 0.7245), por tanto el modelo seleccionado es Xgboost.
