scale_y_continuous( labels = percent_format()) +
labs(title= 'Porcentaje de Clientes que Abandonan',
y= "Porcentaje", x= "Churn") +
theme_bw()
#data %>%  select(-customerID) %>% GGally::ggpairs()
data %>%  select_if(where(is.numeric)) %>% GGally::ggpairs()
#data %>% select(-customerID) -> data
set.seed(1234) # Semilla para aleatorios
split <- data %>%
initial_split(
prop = 0.8, # Porcentaje al train
strata = Churn # Estratificación del muestreo
)
train <- training(split)
dim(train)
test <- testing(split)
dim(test)
receta <- train %>%
recipe(Churn ~ . ) %>% ## Crea la receta
## Eliminar variables que no usaremos
step_rm(customerID) %>%
## Crear nuevas variables (insight desde el EDA)
# step_mutate( account_length_anio= account_length/12 )
## Imputar los datos
# step_impute_mean()
step_impute_knn(TotalCharges ) %>%
## Estandarizacion/Normalizacion de numericas
step_normalize( all_numeric(), -all_outcomes()) %>%
## Crear una categoría "otros" que agrupe a categorias pequeñas
step_other(all_nominal(), -all_outcomes() , threshold = 0.07, other = "otros") %>%
## Crear una categoría "new" para observaciones con labels "no muestreados"
step_novel(all_nominal(), -all_outcomes() , new_level = "new") %>%
## Crear variables indicadoras para cada categoría
step_dummy(all_nominal(), -all_outcomes() ) %>% # Dummy
## Eliminar automáticamente variables con alta correlacion
## para evitar la multicolinealidad xi ~ xj
# step_corr(all_numeric(), -all_outcomes(), threshold = 0.9) %>%
## Tambien podemos eliminar variables con multicolinealidad "a mano"
#step_rm(total_day_charge, total_eve_charge,
#total_night_charge, total_intl_charge) %>% # Eliminar
## Eliminar columnas con varianza cercana a cero
step_nzv(all_predictors()) %>%
themis::step_upsample(Churn, over_ratio = 0.9, skip= TRUE, seed= 123)
View(receta)
set.seed(1234)
cv <- vfold_cv(train, v = 5, repeats = 1, strata = Churn)
cv
set.seed(1234)
cv <- vfold_cv(train, v = 5, repeats = 1, strata = Churn)
cv
metricas <- metric_set(accuracy, sens, spec, bal_accuracy)
metricas
rf_sp <-
rand_forest(
mtry = tune(), trees = tune(), min_n = tune() ) %>%
set_engine("ranger", importance = "impurity") %>%
set_mode("classification")
rf_wflow <-
workflow() %>%
add_recipe(receta) %>%
add_model(rf_sp)
rf_wflow
View(receta)
receta[["template"]][["customerID"]]
receta
summary(receta)
skim(data)
set.seed(123)
rf_grid <- rf_sp %>%
## preguntamos los parametros tuneables del modelo
parameters() %>%
## Vamos a definir un rango para el min_n y mtry
update(min_n= min_n( range= c(70, 170)),
mtry= mtry( range= c(4, 7))) %>%
grid_latin_hypercube(size = 10) #preguntar como se construye la malla
set.seed(123)
rf_tuned <- tune_grid(
rf_wflow, ## Modelo
resamples= cv, ## Crossvalidation
grid = rf_grid, ## Malla de Busqueda
metrics = metricas, ## Metricas
control= control_grid(allow_par = T, save_pred = T) ## Paralel y Pred
)
rf_tuned
ggplot(valores_Pm, aes(x = PaymentMethod, y = N, fill = Churn)) +
geom_col(stat = "identity", position = "dodge") +
geom_text(aes(label = N), vjust = 1.5,
position = position_dodge(.9))
data %>%
count(Churn,TechSupport) %>%
group_by(Churn) %>%
mutate(n_chur=sum(n),
porcentaje_personas=n/n_chur) %>%
ungroup() %>%
ggplot(aes(Churn,
porcentaje_personas,
fill = TechSupport)) +
geom_col(position = "dodge") +
geom_text(aes(label = scales::percent(porcentaje_personas,
accuracy = 0.01)),
vjust = -0.8,
position = position_dodge(.9))
library(tidyverse)
library(magrittr)
library(skimr)
library(janitor)
library(tidymodels)
library(ranger)
library(xgboost)
library(vip)
data <- read_csv('Data/WA_Fn-UseC_-Telco-Customer-Churn.csv',
show_col_types = FALSE)
data %>%
glimpse %>%
gt::gt()
data %>%
summarise_all(list(
.n=~sum(!is.na(.)),
.na=~sum(is.na(.)),
.min=~min(.,na.rm = T),
.max=~max(.,na.rm = T),
.clase=~class(.),
.valor_distinto=~n_distinct(.)
)) %>% mutate(across(everything(),~as.character(.))) %>%
pivot_longer(everything(),
names_to = c("varible",".value"),
names_sep = c("_\\.")) %>% gt::gt()
#Convertir a factor
data %>%
mutate( Churn = factor(Churn,
levels= c("Yes","No"),
labels= c("si", "no"))
) -> data
data %>%
mutate(
SeniorCitizen = factor(SeniorCitizen,
levels = c(0, 1), labels = c('no', 'si')),
gender = factor(gender,
levels = c('Female', 'Male'), labels = c('Mujeres', 'Hombres')),
Partner = factor(Partner,
levels = c('Yes', 'No'), labels = c('si', 'No')),
Dependents = factor(Dependents,
levels = c('Yes', 'No'), labels = c('si', 'No')),
PhoneService = factor(PhoneService,
levels = c('Yes', 'No'), labels = c('si', 'No')),
PaperlessBilling = factor(PaperlessBilling,
levels = c('Yes', 'No'), labels = c('si', 'No')),
MultipleLines = factor(MultipleLines,
levels = c('Yes', 'No', "No phone service"), labels = c('si', 'no', 'sin servicio')),
InternetService = factor(InternetService,
levels = c('DSL', 'Fiber optic', 'No'), labels = c('DSL', 'Fibra optica', 'No')),
OnlineSecurity = factor(OnlineSecurity,
levels = c('No', 'Yes', 'No internet service'), labels = c('No', 'Yes', 'sin servicio')),
OnlineBackup = factor(OnlineBackup,
levels = c('Yes', 'No', 'No internet service'), labels = c('si', 'no', 'sin servicio')),
DeviceProtection = factor(DeviceProtection,
levels = c('Yes', 'No', 'No internet service'), labels = c('si', 'no', 'sin servicio')),
TechSupport = factor(TechSupport,
levels = c('Yes', 'No', 'No internet service'), labels = c('si', 'no', 'sin servicio')),
StreamingTV = factor(StreamingTV,
levels = c('Yes', 'No', 'No internet service'), labels = c('si', 'no', 'sin servicio')),
StreamingMovies = factor(StreamingMovies,
levels = c('Yes', 'No', 'No internet service'), labels = c('si', 'no', 'sin servicio')),
Contract = factor(Contract,
levels = c('Month-to-month', 'One year', 'Two year'), labels = c('mes a mes', 'un año', 'dos años')),
PaymentMethod = factor(PaymentMethod,
levels = c('Electronic check', 'Mailed check', 'Bank transfer (automatic)', 'Credit card (automatic)'),
labels = c('cheque electronico', 'cheque mail', 'transferencia bancaria', 'transferencia automatica'))
) -> data
skim(data)
data %>%
reframe(
tibble(
Descrip= c('P_0', 'P_02', 'P_25', 'P_50' , 'P_75', 'P_98', 'P_100') ,
Valor= quantile( TotalCharges, c(0, 0.2, 0.25, 0.50 ,0.75, 0.98, 1), na.rm= T)
)
) %>%
gt::gt()
#Media por Partner
data %>%
group_by(Partner) %>%
summarise(media=mean(TotalCharges,
na.rm =T )) %>%
gt::gt()
#Distribuciòn de TotalCharges por Partner
data %>%
ggplot(aes(TotalCharges,
color=Partner))+
geom_density()+
scale_y_continuous(labels = scales::number_format())+
theme_dark()
data %>%
group_by(SeniorCitizen, Churn) %>%
summarise(
N = n(),
Porc = round(100*N/nrow(data),2)
) %>%
mutate(Porc_grupo = round(100*N/sum(N),2)) -> valores_Sc
valores_Sc %>%
ungroup() %>%
gt::gt()
# Comentado por conflictos con paquete
# tigerstats::rowPerc(xtabs(~SeniorCitizen+Churn, data=data) )
ggplot(valores_Sc, aes(x = SeniorCitizen, y = Porc_grupo, fill = Churn)) +
geom_col(stat = "identity", position = "dodge") +
geom_text(aes(label = Porc_grupo), vjust = 1.5,
position = position_dodge(.9))
valores_Ml <- data %>%
count(Churn,MultipleLines) %>%
group_by(Churn) %>%
mutate(n_chur=sum(n),
porcentaje_personas=n/n_chur) %>%
ungroup()
valores_Ml %>%
gt::gt()%>%
gt::fmt_percent(columns=porcentaje_personas)
valores_Ml %>%
ggplot(aes(Churn, y = porcentaje_personas, fill = MultipleLines)) +
geom_col(position = "dodge") +
geom_text(aes(label = scales::percent(porcentaje_personas,accuracy = 0.01)), vjust = -0.8,
position = position_dodge(.9))
data %>%
count(Churn,TechSupport) %>%
group_by(Churn) %>%
mutate(n_chur=sum(n),
porcentaje_personas=n/n_chur) %>%
ungroup() %>%
ggplot(aes(Churn,
porcentaje_personas,
fill = TechSupport)) +
geom_col(position = "dodge") +
geom_text(aes(label = scales::percent(porcentaje_personas,
accuracy = 0.01)),
vjust = -0.8,
position = position_dodge(.9))
data %>%
count(Churn,PaymentMethod) %>%
group_by(Churn) %>%
mutate(n_chur=sum(n),
porcentaje_personas=n/n_chur) %>%
ungroup() %>%
ggplot(aes(Churn,
porcentaje_personas,
fill = PaymentMethod)) +
geom_col(position = "dodge") +
geom_text(aes(label = scales::percent(porcentaje_personas,
accuracy = 0.1)),
vjust = -0.8,
position = position_dodge(.9))
ggplot(valores_Pm, aes(x = PaymentMethod, y = N, fill = Churn)) +
geom_col(stat = "identity", position = "dodge") +
geom_text(aes(label = N), vjust = 1.5,
position = position_dodge(.9))
ggplot(data, aes(x = PaymentMethod, y = MonthlyCharges, fill = Churn)) +
geom_boxplot()
data %>% tabyl(Churn, Dependents ) -> t1
t1 %>% adorn_totals(c("row", "col")) %>% adorn_percentages("all") %>%
adorn_pct_formatting(rounding = "half up", digits = 0) %>% adorn_ns() %>%
adorn_title("combined") %>% knitr::kable()
data %>% count(Churn, Dependents) %>%
mutate(porc = n / sum(n)) %>%
ggplot(aes(fill=Dependents, y=porc, x=Churn)) +
geom_col(position="stack") +
geom_text(aes(label=scales::percent(porc)),position = position_stack(vjust=0.5))+
scale_y_continuous(labels = scales::percent_format())
data %>% tabyl(Churn,OnlineSecurity ) -> t2
t2 %>% adorn_totals(c("row", "col")) %>% adorn_percentages("all") %>%
adorn_pct_formatting(rounding = "half up", digits = 0) %>% adorn_ns()%>% adorn_title("combined")%>% knitr::kable()
data %>% count(Churn, OnlineSecurity) %>%
mutate(porc = n / sum(n)) %>%
ggplot(aes(fill=OnlineSecurity, y=porc, x=Churn)) +
geom_col(position="stack") +
geom_text(aes(label=scales::percent(porc)),position = position_stack(vjust=0.5))+
scale_y_continuous(labels = scales::percent_format())
data %>% tabyl(Churn,StreamingMovies) -> t3
t3 %>% adorn_totals(c("row", "col")) %>% adorn_percentages("all") %>%
adorn_pct_formatting(rounding = "half up", digits = 0) %>% adorn_ns()%>% adorn_title("combined")%>% knitr::kable()
data %>% count(Churn, StreamingMovies) %>%
mutate(porc = n / sum(n)) %>%
ggplot(aes(fill=StreamingMovies, y=porc, x=Churn)) +
geom_col(position="stack") +
geom_text(aes(label=scales::percent(porc)),position = position_stack(vjust=0.5))+
scale_y_continuous(labels = scales::percent_format())
data %>%  group_by(Churn) %>%
summarise(n = n(),
promedio = mean(TotalCharges,na.rm = T),
n_missing = sum(is.na(TotalCharges)),
desv = sd(TotalCharges, na.rm =T)) -> t4
t4 %>%
gt::gt()
data %>%
ggplot(aes(x = Churn, y = TotalCharges, fill = Churn)) +
geom_boxplot() +
stat_summary(fun = mean, geom = "point", shape = 3, size = 3,
color = "white", position = position_dodge(width = 0.75)) +
labs(title = "Churn vs Total Charges",
x = "Churn",
y = "Total Charges") +
theme_minimal()
ggplot(data, aes(x = Churn, y = MonthlyCharges, fill = PaymentMethod)) +
geom_boxplot()
data %>%  group_by(Churn,Dependents) %>%
summarise(n = n(),
promedio = mean(MonthlyCharges,na.rm = T),
n_missing = sum(is.na(MonthlyCharges)),
desv = sd(MonthlyCharges, na.rm =T),
.groups="drop")  -> t5
t5 %>%
gt::gt() %>%
gt::fmt_number(columns = c(promedio,desv),
decimals = 2)
data %>%
ggplot(aes(x = Churn, y = MonthlyCharges, fill = Dependents)) +
geom_boxplot() +
stat_summary(fun = mean, geom = "point", shape = 3, size = 3, color = "white", position = position_dodge(width = 0.75)) +
labs(title = "Monthtly Charges for Dependents vs Churn",
x = "Churn",
y = "Monthly Charges")
data %>%  select_if(where(is.numeric)) %>% GGally::ggpairs()
data %>%
group_by(Churn) %>%
count(name = "frec") %>%
ungroup() %>%
mutate( Porc= frec/sum(frec)) %>%
gt::gt() %>%
gt::fmt_percent(columns=Porc)
data %>%
group_by(Churn) %>%
count( name = 'frec') %>%
ungroup() %>%
mutate( Porc= frec/sum(frec)) %>%
ggplot( aes(x= Churn, y= Porc)) +
geom_segment( aes(xend= Churn, y=0, yend=Porc),
color= "steelblue", linewidth= 1) +
geom_point( size=5, color= "steelblue") +
coord_flip() +
scale_y_continuous( labels = percent_format()) +
labs(title= 'Porcentaje de Clientes que Abandonan',
y= "Porcentaje", x= "Churn") +
theme_bw()
#data %>% select(-customerID) -> data
set.seed(1234) # Semilla para aleatorios
split <- data %>%
initial_split(
prop = 0.8, # Porcentaje al train
strata = Churn # Estratificación del muestreo
)
train <- training(split)
dim(train)
test <- testing(split)
dim(test)
receta <- train %>%
recipe(Churn ~ . ) %>% ## Crea la receta
## Eliminar variables que no usaremos
step_rm(customerID) %>%
## Crear nuevas variables (insight desde el EDA)
# step_mutate( account_length_anio= account_length/12 )
## Imputar los datos
# step_impute_mean()
step_impute_knn(TotalCharges ) %>%
## Estandarizacion/Normalizacion de numericas
step_normalize( all_numeric(), -all_outcomes()) %>%
## Crear una categoría "otros" que agrupe a categorias pequeñas
step_other(all_nominal(), -all_outcomes() , threshold = 0.07, other = "otros") %>%
## Crear una categoría "new" para observaciones con labels "no muestreados"
step_novel(all_nominal(), -all_outcomes() , new_level = "new") %>%
## Crear variables indicadoras para cada categoría
step_dummy(all_nominal(), -all_outcomes() ) %>% # Dummy
## Eliminar automáticamente variables con alta correlacion
## para evitar la multicolinealidad xi ~ xj
# step_corr(all_numeric(), -all_outcomes(), threshold = 0.9) %>%
## Tambien podemos eliminar variables con multicolinealidad "a mano"
#step_rm(total_day_charge, total_eve_charge,
#total_night_charge, total_intl_charge) %>% # Eliminar
## Eliminar columnas con varianza cercana a cero
step_nzv(all_predictors()) %>%
themis::step_upsample(Churn, over_ratio = 0.9, skip= TRUE, seed= 123)
set.seed(1234)
cv <- vfold_cv(train, v = 5, repeats = 1, strata = Churn)
cv
metricas <- metric_set(accuracy, sens, spec, bal_accuracy)
metricas
rf_sp <-
rand_forest(
mtry = tune(), trees = tune(), min_n = tune() ) %>%
set_engine("ranger", importance = "impurity") %>%
set_mode("classification")
rf_wflow <-
workflow() %>%
add_recipe(receta) %>%
add_model(rf_sp)
rf_wflow
rf_wflow <-
workflow() %>%
add_recipe(receta) %>%
add_model(rf_sp)
rf_wflow
set.seed(123)
rf_grid <- rf_sp %>%
## preguntamos los parametros tuneables del modelo
parameters() %>%
## Vamos a definir un rango para el min_n y mtry
update(min_n= min_n( range= c(70, 170)),
mtry= mtry( range= c(4, 7))) %>%
grid_latin_hypercube(size = 10) #preguntar como se construye la malla
set.seed(123)
rf_tuned <- tune_grid(
rf_wflow, ## Modelo
resamples= cv, ## Crossvalidation
grid = rf_grid, ## Malla de Busqueda
metrics = metricas, ## Metricas
control= control_grid(allow_par = T, save_pred = T) ## Paralel y Pred
)
rf_tuned
show_best(rf_tuned, metric = 'accuracy', n = 10)
show_best(rf_tuned, metric = 'sens', n = 10)
show_best(rf_tuned, metric = 'spec', n = 10)
show_best(rf_tuned, metric = 'bal_accuracy', n = 10)
set.seed(123)
rf_grid_2 <- crossing(
min_n = seq(114, 118, 2),
mtry = c(4, 5),
trees= seq(1270, 1570, 100)
)
rf_grid_2
set.seed(123)
rf_tuned_2 <- tune_grid(
rf_wflow, ## Modelo
resamples= cv, ## Crossvalidation
grid = rf_grid_2, ## Malla de Busqueda
metrics = metricas, ## Metricas
control= control_grid(allow_par = T, save_pred = T) ## Paralel y Pred
)
rf_tuned_2
show_best(rf_tuned_2, metric = 'accuracy', n = 10)
show_best(rf_tuned_2, metric = 'sens', n = 10)
show_best(rf_tuned_2, metric = 'spec', n = 10)
show_best(rf_tuned_2, metric = 'bal_accuracy', n = 10)
## Definir la mejor combinacion
rf_pars_fin <- select_best(rf_tuned, metric = 'sens')
## Finalizar (darle valores a parametros tuneables) el workflow
rf_wflow_fin <-
rf_wflow %>%
finalize_workflow(rf_pars_fin)
rf_wflow_fin
rf_fitted <- fit(rf_wflow_fin, train)
rf_fitted
rf_model_fin <- extract_fit_parsnip(rf_fitted)
train %>%
predict(rf_fitted , new_data = . ) %>%
mutate(Real= train$Churn) %>%
conf_mat(truth = Real, estimate = .pred_class ) %>%
summary
test %>%
predict(rf_fitted, new_data = . ) %>%
mutate(Real= test$Churn) %>%
conf_mat(truth = Real, estimate = .pred_class ) %>%
summary
library(vip)
rf_model_fin %>%
vip(geom = "point")
xgb_sp <- boost_tree(mtry = tune(), trees = tune(),
loss_reduction = tune(), learn_rate= tune() ) %>%
set_engine("xgboost") %>%
set_mode("classification")
xgb_sp %>%
translate()
receta_prep = prep(receta, train)
finalize(mtry(), bake(receta_prep, new_data = NULL ))
set.seed(123)
xgb_grid <- xgb_sp %>%
parameters() %>%
finalize(bake(receta_prep, new_data = NULL)) %>%
grid_latin_hypercube(size = 20)
xgb_grid
xgb_wflow <-
workflow() %>%
add_recipe(receta) %>%
add_model(xgb_sp)
xgb_wflow
set.seed(123)
xgb_tuned <- tune_grid(
xgb_wflow,
resamples= cv,
grid = xgb_grid,
metrics = metricas,
control= control_grid(allow_par = T, save_pred = T)
)
xgb_tuned
show_best(xgb_tuned, metric = 'accuracy', n = 10)
show_best(xgb_tuned, metric = 'sens', n = 10)
show_best(xgb_tuned, metric = 'spec', n = 10)
show_best(xgb_tuned, metric = 'bal_accuracy', n = 10)
xgb_pars_fin <- select_best(xgb_tuned, metric = 'sens')
xgb_wflow_fin <-
xgb_wflow %>%
finalize_workflow(xgb_pars_fin)
xgb_wflow_fin
xgb_fitted <- fit(xgb_wflow_fin, train)
xgb_fitted
xgb_model_fin <- pull_workflow_fit(xgb_fitted)
xgb_model_fin
train %>%
predict(xgb_fitted , new_data = . ) %>%
mutate(Real= train$Churn) %>%
conf_mat(truth = Real, estimate = .pred_class ) %>%
summary
test %>%
predict(xgb_fitted , new_data = . ) %>%
mutate(Real= test$Churn) %>%
conf_mat(truth = Real, estimate = .pred_class ) %>%
summary
